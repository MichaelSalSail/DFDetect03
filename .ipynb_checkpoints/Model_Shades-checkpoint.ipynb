{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frame(video_path, output_dir=\"\"):\n",
    "    '''\n",
    "    Saves the first frame of the video in the output_dir.\n",
    "    \n",
    "    Args:\n",
    "        video_path: path of the video including the video name.\n",
    "        output_dir: path to save the frame, optional parameter.\n",
    "    \n",
    "    Returns:\n",
    "        full directory of the saved image.\n",
    "    '''\n",
    "    # creating a video capture object\n",
    "    video_object = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # get the first frame of the video\n",
    "    ret,frame = video_object.read()\n",
    "\n",
    "    # save\n",
    "    result=output_dir+\"/\"+\"test_shades.png\"\n",
    "    cv2.imwrite(result, frame)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_shades(image_dir, output_dir=\"\"):\n",
    "    '''\n",
    "    Uses the default VGG16 model for image classification.\n",
    "    VGG16 is able to detect 1000 object types in photos.\n",
    "    We are focused on sunglasses classification.\n",
    "    \n",
    "    Args:\n",
    "        image_dir: directory of input image.\n",
    "        output_dir: location for the .txt file, optional parameter.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # resizes an image to required VGG16 dimensions.\n",
    "    image = load_img(image_dir, target_size=(224, 224))\n",
    "    # convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "    # reshape data for the model\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    # prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    # load the model\n",
    "    model = VGG16()\n",
    "    # predict the probability across all output classes\n",
    "    yhat = model.predict(image)\n",
    "    # convert the probabilities to class labels\n",
    "    label = decode_predictions(yhat)\n",
    "    # store all relevant information in a .txt file\n",
    "    full_name=output_dir+\"/\"+\"result.txt\"\n",
    "    file1 = open(full_name,\"w\")\n",
    "    # put it all in a list then append to the .txt file\n",
    "    result=list()\n",
    "    result.append('Top 5 Object Detection Predictions\\n')\n",
    "    top_5_shades=False\n",
    "    for i in range(0,5):\n",
    "        result.append('%s (%.2f%%)\\n' % (label[0][i][1], label[0][i][2]*100))\n",
    "        # label 'n04356056' is 'sunglasses, dark glasses, shades'\n",
    "        if (label[0][i][0]=='n04356056'):\n",
    "            top_5_shades=True\n",
    "    if (top_5_shades==True):\n",
    "        result.append(\"There appears to be sunglasses. Larger glasses are hard to deepfake.\")\n",
    "    else:\n",
    "        result.append(\"No sunglasses detected.\")\n",
    "    file1.writelines(result)\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------Look here-----------------------------------------\n",
    "# The directories for the application repository are different from the DFDetect03 repository!\n",
    "# Change the variables as you see fit.\n",
    "\n",
    "pre1 = os.getcwd()\n",
    "pre2 = \"/data/deepfake-detection-challenge/test_videos\"\n",
    "video_path = pre1+pre2+\"/adohdulfwb.mp4\"\n",
    "\n",
    "output_dir = \"eyeblink data labels/data/temp\"\n",
    "\n",
    "frame_loc=save_frame(video_path, output_dir)\n",
    "detect_shades(frame_loc, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
